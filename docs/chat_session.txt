Component 1: Detailed Local Data Structure (The "Ground Truth")

   * Implementation: This is the "Stateful Psychometric Summary" we discussed. In app.py, you would augment the session to hold a list of
     structured objects. For every question answered, you'd append a new object.
   * Data Points per Object:
       * question_id
       * topic
       * response_timestamp_start
       * response_timestamp_end
       * response_time_sec (calculated from timestamps)
       * answer_chosen
       * is_correct
       * hints_requested (count)
       * student_initiated_interactions: A list of summaries of any non-answer messages from the user for that question (e.g., ["asked for
         hint", "expressed confusion"]).
   * Role: This is the objective, factual record of the session. It's compact and perfect for sending to the LLM on every turn.

  Component 2: AI-Generated Psychometric Summary (The "Evolving Insight")

   * Implementation: The response from the Gemini API would need to be extended. Currently, it gives a decision for the next action. We
     would modify the prompt and the expected JSON output to also include a summary of its current understanding of the student.
   * New JSON fields from LLM:
       * student_model_summary: {
           * detected_strengths: ["Topic A", "Topic C"],
           * detected_weaknesses: ["Topic B"],
           * estimated_fatigue_level: "Low" (e.g., Low, Medium, High),
           * estimated_engagement: "High",
           * learning_curve_trend: "Positive"
          }
   * Role: This is the AI's subjective interpretation of the data. It represents the "student model" itself. On each turn, you would send
     the previous summary back to the AI along with the new data from Component 1. This allows the AI to iteratively refine its own model
     of the student without re-reading the entire history.

  Component 3: On-Demand Full History (The "Deep Dive")

   * Implementation: This is a clever mechanism to handle edge cases.
       1. The standard prompt (containing Components 1 & 2) would be used for >95% of calls.
       2. We would add a new possible value to the action field in the LLM's response, such as "REQUEST_FULL_HISTORY".
       3. In app.py, if the llm_decision.get("action") is "REQUEST_FULL_HISTORY", the application would make a second, immediate call to
          gemini_service, but this time, it would send the complete, verbose chat_history.
       4. The prompt would need to instruct the AI that this is a special, one-off request to re-evaluate its student model based on the
          full context, and that it should then return to the normal, summarized mode on the next turn.
   * Role: This is the safety net. It gives the AI an escape hatch if it feels the summarized data is insufficient to make a high-quality
     decision. For example, it might trigger this if the summarized data seems contradictory or if it wants to analyze the specific
     phrasing a student used during a period of frustration.